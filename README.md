# Robot Pose Helper

## Проект: Нейросетевой костыль для человекоподобных роботов

Проект разделён на два основных подпроекта:

- `model_training` — сбор данных, подготовка датасета и обучение нейросети.
- `model_runtime` — запуск обученной модели и предсказание движения в реальном времени.

Внутри используется `mediapipe` для детекции позы, `opencv-python` для работы с камерой и отрисовки скелета, а также `scikit-learn` для простой MLP‑модели.

### Требования

- Python 3.10+.
- Веб‑камера.
- Зависимости:
  - либо из `requirements.txt`,
  - либо через установку проекта как пакета с помощью `pyproject.toml`.

Установка зависимостей (простой вариант, через `requirements.txt`):

```bash
# Важно: используйте python -m pip для гарантии установки в правильное окружение
python -m pip install -r requirements.txt
```

Установка как пакета (через `pyproject.toml`, чтобы получить единый набор зависимостей и dev‑инструменты):

```bash
python -m pip install .
```

Для разработки (форматирование, линтеры, тесты):

```bash
python -m pip install ".[dev]"
```

**Примечание**: Если у вас установлено несколько версий Python, убедитесь, что используете правильный интерпретатор. Команда `python -m pip` гарантирует установку пакетов в то же окружение, что и интерпретатор `python`.

### Конфигурация (`settings.ini`)

Основные параметры видеопотока и детектора позы вынесены в файл `settings.ini` в корне проекта:

```ini
[video]
; Индекс камеры в системе (0 — первая найденная веб‑камера)
camera_index = 0

; Размер окна предпросмотра
window_width = 1280
window_height = 720

; Как часто обновлять/записывать углы (секунды)
angle_update_interval_sec = 0.2

[pose]
; Порог уверенности детектора позы Mediapipe (0.0–1.0)
detection_confidence = 0.5
```

- Если `settings.ini` отсутствует, используются значения по умолчанию.  
- Параметры читаются в модуле `model_training.config` и автоматически используются как при сборе данных, так и в runtime.

### Подпроект `model_training`

Файлы:

- `model_training/capture_angles.py` — запись углов из веб‑камеры в `data.csv`.
- `model_training/dataset.py` — загрузка `data.csv`, базовые проверки и подготовка признаков/меток.
- `model_training/train_model.py` — обучение MLP‑нейросети, сохранение модели и метрик.

#### Сбор данных для обучения

Для обучения используется изображение с камеры. Человек должен помещаться в кадр полностью, иначе углы вычисляться не будут.

Запуск окна захвата:

```bash
python -m model_training.capture_angles
```

Управление:

- Пробел — включить/выключить запись в файл.
- `q` — закрыть окно и завершить программу.

Данные записываются в файл `data.csv` в корне проекта. Колонки с углами соответствуют списку `CSV_ANGLE_KEYS` из `model_training.config`.

#### Обучение модели

После того как вы собрали достаточно данных:

```bash
python -m model_training.train_model
```

Скрипт:

- загружает `data.csv` (с проверками: наличие файла, корректные колонки, отсутствие полностью пустого датасета),
- формирует скользящие окна из данных: последние 3 тика → углы следующего тика (временной ряд),
- обучает MLP‑регрессор для предсказания углов следующего тика на основе окна из нескольких предыдущих тиков,
- сохраняет:
  - файл модели `models/movement_model.joblib`,
  - метрики качества (MAE, RMSE, процент ошибки) в `models/metrics.json`.

**Важно**: 
- Модель обучается предсказывать углы следующего тика на основе окна из 3 предыдущих тиков
- Данные должны быть собраны последовательно (движения человека в реальном времени)
- Минимум нужно 4+ последовательных записи для создания хотя бы одного окна

Сообщения об ошибках и статусе выводятся через стандартный модуль `logging`.

### Подпроект `model_runtime`

Файл:

- `model_runtime/realtime_predict.py` — запуск камеры, расчёт углов и предсказание движения по обученной модели.

#### Запуск runtime

После успешного обучения модели:

```bash
python -m model_runtime.realtime_predict
```

Скрипт:

- загружает сохранённую модель из `models/movement_model.joblib`,
- использует те же параметры окна и камеры, что и в `settings.ini`,
- на каждом тике (с частотой из `angle_update_interval_sec`):
  1. **Детектирует позу** с помощью Mediapipe,
  2. **Вычисляет текущие углы** суставов с помощью `angles.py`,
  3. **Сохраняет углы в историю** (поддерживается окно из последних 3 тиков),
  4. **Предсказывает углы следующего тика** на основе окна из нескольких предыдущих тиков (когда история заполнена),
  5. **Сравнивает предсказанные углы с реальными** углами в следующем тике,
  5. **Отображает метрики**:
     - `Accuracy`: точность предсказания в процентах (чем выше, тем лучше),
     - `Error`: ошибка предсказания в процентах (чем ниже, тем лучше),
     - Цвет индикатора: зелёный (ошибка ≤10%), жёлтый (10-25%), красный (>25%),
  6. **Отрисовывает скелет** на кадре.

**Логика работы**:
- Модель использует скользящее окно из 3 предыдущих тиков для предсказания следующего
- Это позволяет учитывать динамику движения и улучшает качество предсказаний
- В начале работы система собирает историю (первые 3 тика), затем начинает предсказывать
- В следующем тике предсказанные углы сравниваются с реальными углами, полученными с камеры
- Метрики обновляются каждый тик при наличии данных для сравнения

Выход из программы — клавиша `q` в окне с видеопотоком.

### Тесты

Базовые тесты находятся в каталоге `tests/`. Для запуска используется `pytest`:

```bash
pytest
```

Сейчас покрыт векторный расчёт углов в `angles.py`; при необходимости можно расширять набор тестов (например, для загрузки датасета, обучения модели и т.д.).

### Как это работает

1. **Сбор данных**: Записываются последовательные углы суставов человека с камеры в `data.csv` (существует мысль о добавлении возможности обучения по видео .mp3).
2. **Обучение**: Модель учится предсказывать углы следующего тика на основе окна из 3 предыдущих тиков (регрессия временных рядов со скользящим окном).
3. **Runtime**: Модель собирает историю углов, предсказывает углы следующего тика на основе окна из нескольких предыдущих тиков и сравнивает их с реальными значениями, показывая точность предсказания.

### Идея и ограничения

Модель можно использовать для предсказания движений робота на основе текущей позы и использовать эти данные в помощь основному ядру движения робота. Важно:

- собрать достаточно последовательных данных (минимум 4 примера для одного окна, рекомендуется 20+ для качественного обучения),
- данные должны быть собраны в реальном времени (последовательно, без пропусков),
- качество предсказания зависит от количества и разнообразия данных,
- при необходимости можно доработать архитектуру модели (добавить LSTM/GRU для лучшей работы с временными рядами).

Проект остаётся экспериментальным и очень СЫРЫМ!!! Требует адаптации под конкретного робота и задачу управления, но структура кода и конфигурация уже ближе к промышленному стилю.

### Лицензия

Проект распространяется под лицензией MIT. См. файл [LICENSE](LICENSE) для подробностей. Приветствуется указывать автора данного ПО при использовании в том или ином виде в составе других ПО
